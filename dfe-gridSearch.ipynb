{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujay/miniconda3/envs/mtp/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, GRU, SimpleRNN, Embedding, Conv1D, MaxPooling1D, Masking\n",
    "from keras import optimizers,regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_train(data, n_steps):\n",
    "    X_train, Y_train= list(), list()\n",
    "    final_choices = [int(x[-1]) for x in data]\n",
    "    features = [x[:-1] for x in data]\n",
    "    # making training data \n",
    "    count = 0\n",
    "    for feat,f_choice in zip(features, final_choices):\n",
    "        if(len(feat)//2 <= n_steps):\n",
    "            X_train.append(feat)\n",
    "            Y_train.append(f_choice)\n",
    "            count += 1\n",
    "        else:\n",
    "            for i in range(len(feat)//2-n_steps):\n",
    "                end_idx = 2*(i+n_steps)\n",
    "                X_train.append(feat[2*i:end_idx])\n",
    "                Y_train.append(feat[end_idx])\n",
    "            X_train.append(feat[(len(feat)-2*n_steps):len(feat)])\n",
    "            Y_train.append(f_choice)\n",
    "#     print(count)\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_test(data, n_steps):\n",
    "    X_test, Y_test= list(), list()\n",
    "    final_choices = [int(x[-1]) for x in data]\n",
    "    features = [x[:-1] for x in data]\n",
    "    # making training data \n",
    "    count = 0\n",
    "    for feat,f_choice in zip(features, final_choices):\n",
    "        if(len(feat)//2 <= n_steps):\n",
    "            X_test.append(feat)\n",
    "            Y_test.append(f_choice)\n",
    "            count += 1\n",
    "        else:\n",
    "            X_test.append(feat[(len(feat)-2*n_steps):len(feat)])\n",
    "            Y_test.append(f_choice)\n",
    "#     print(count)\n",
    "    return X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(name, n_steps, flag):\n",
    "    infile = open(name, 'r')\n",
    "    lines = infile.readlines()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        data.append([float(x) for x in line.split(',')])\n",
    "#     normalise_outcomes(data)\n",
    "    if(flag):\n",
    "        return create_dataset_train(data, n_steps)\n",
    "    else:\n",
    "        return create_dataset_test(data, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(n_steps):\n",
    "    X_train, y_train = parse_dataset('data/estimation_without_padding.csv',n_steps, 1)\n",
    "    X_test, y_test = parse_dataset('data/competition_without_padding.csv',n_steps, 0)\n",
    "    \n",
    "    maxlen = max(max([len(x) for x in X_train]), max([len(x) for x in X_test]))\n",
    "    \n",
    "    X_train = pad_sequences(X_train, padding='post', value=-100.0, dtype=float, maxlen=maxlen)\n",
    "    X_test = pad_sequences(X_test, padding='post', value=-100.0, dtype=float, maxlen=maxlen)\n",
    "    \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], n_steps, 2))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], n_steps, 2))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_config(config):\n",
    "    \n",
    "    n_steps, n_units, n_epochs, n_batch, n_layers = config\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = get_dataset(n_steps)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=-100.0, input_shape=(None, X_train.shape[2])))\n",
    "    if(n_layers == 1):\n",
    "        model.add(LSTM(n_units, activation='relu', input_shape=(None, X_train.shape[2])))\n",
    "    else:\n",
    "        model.add(LSTM(n_units, activation='relu', input_shape=(None, X_train.shape[2]), return_sequences=True))\n",
    "        \n",
    "        while(n_layers-2):\n",
    "            model.add(LSTM(n_units, activation='relu', return_sequences=True))\n",
    "            n_layers -= 1\n",
    "        model.add(LSTM(n_units, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=n_epochs, batch_size=n_batch)\n",
    "    \n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    scores1 = model.evaluate(X_train, y_train, verbose=0)\n",
    "#     print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    return np.array([round(scores[1]*100, 2), round(scores1[1]*100, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_configs():\n",
    "    n_steps = [20]\n",
    "    n_units = [10]\n",
    "    n_epochs = [20]\n",
    "    n_batch = [20]\n",
    "    n_layers = [1]\n",
    "    \n",
    "    # create configs\n",
    "    configs = list()\n",
    "    for i in n_steps:\n",
    "        for j in n_units:\n",
    "            for k in n_epochs:\n",
    "                for l in n_batch:\n",
    "                    for m in n_layers:\n",
    "                        cfg = [i, j, k, l, m]\n",
    "                        configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs))\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_evaluate_config(config):\n",
    "    n_avg = 1\n",
    "    ans = np.array([0.0,0.0])\n",
    "    \n",
    "    for i in range(n_avg):\n",
    "        ans += evaluate_config(config)\n",
    "    ans /= n_avg\n",
    "    \n",
    "    return (config, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configs: 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, None, 2)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                520       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 553\n",
      "Trainable params: 553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2836 samples, validate on 1198 samples\n",
      "Epoch 1/20\n",
      "2836/2836 [==============================] - 7s 2ms/step - loss: 1.6257 - acc: 0.4531 - val_loss: 0.9362 - val_acc: 0.4766\n",
      "Epoch 2/20\n",
      "2836/2836 [==============================] - 5s 2ms/step - loss: 0.7560 - acc: 0.5402 - val_loss: 0.8256 - val_acc: 0.4491\n",
      "Epoch 3/20\n",
      "2836/2836 [==============================] - 6s 2ms/step - loss: 0.7105 - acc: 0.5529 - val_loss: 0.7804 - val_acc: 0.4407\n",
      "Epoch 4/20\n",
      "2836/2836 [==============================] - 6s 2ms/step - loss: 0.6863 - acc: 0.5642 - val_loss: 0.7663 - val_acc: 0.4533\n",
      "Epoch 5/20\n",
      "2836/2836 [==============================] - 5s 2ms/step - loss: 0.6720 - acc: 0.5786 - val_loss: 0.7617 - val_acc: 0.4725\n",
      "Epoch 6/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.6571 - acc: 0.6083 - val_loss: 0.7435 - val_acc: 0.4766\n",
      "Epoch 7/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.6461 - acc: 0.6206 - val_loss: 0.7524 - val_acc: 0.4775\n",
      "Epoch 8/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.6416 - acc: 0.6259 - val_loss: 0.7472 - val_acc: 0.4967\n",
      "Epoch 9/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.6210 - acc: 0.6446 - val_loss: 0.7289 - val_acc: 0.5134\n",
      "Epoch 10/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.6082 - acc: 0.6601 - val_loss: 0.7262 - val_acc: 0.5326\n",
      "Epoch 11/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.5950 - acc: 0.6809 - val_loss: 0.7308 - val_acc: 0.5192\n",
      "Epoch 12/20\n",
      "2836/2836 [==============================] - 5s 2ms/step - loss: 0.5877 - acc: 0.6841 - val_loss: 0.7308 - val_acc: 0.5175\n",
      "Epoch 13/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.5787 - acc: 0.6950 - val_loss: 0.7149 - val_acc: 0.5351\n",
      "Epoch 14/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.5644 - acc: 0.7042 - val_loss: 0.7429 - val_acc: 0.5225\n",
      "Epoch 15/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.5545 - acc: 0.7225 - val_loss: 0.7232 - val_acc: 0.5401\n",
      "Epoch 16/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.5472 - acc: 0.7232 - val_loss: 0.7426 - val_acc: 0.5301\n",
      "Epoch 17/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.5368 - acc: 0.7331 - val_loss: 0.7315 - val_acc: 0.5467\n",
      "Epoch 18/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.5312 - acc: 0.7341 - val_loss: 0.7188 - val_acc: 0.5609\n",
      "Epoch 19/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.5184 - acc: 0.7507 - val_loss: 0.7109 - val_acc: 0.5960\n",
      "Epoch 20/20\n",
      "2836/2836 [==============================] - 4s 2ms/step - loss: 0.5205 - acc: 0.7479 - val_loss: 0.7080 - val_acc: 0.5776\n",
      "([20, 10, 20, 20, 1], array([57.76, 75.85]))\n"
     ]
    }
   ],
   "source": [
    "configs = get_configs()\n",
    "\n",
    "# repeat_evaluate_config([5, 5, 5, 20, 1])\n",
    "\n",
    "outfile = open('results/grid-search.txt', 'w')\n",
    "# outfile.write(str(repeat_evaluate_config([5, 5, 2, 20, 1])))\n",
    "# outfile.close()\n",
    "for config in configs:\n",
    "    out = repeat_evaluate_config(config)\n",
    "    print(out)\n",
    "    outfile.write(str(out))\n",
    "outfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
