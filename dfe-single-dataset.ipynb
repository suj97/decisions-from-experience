{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, GRU, SimpleRNN, Embedding, Conv1D, MaxPooling1D\n",
    "from keras import optimizers,regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, n_steps):\n",
    "    X_train, Y_train, X_test, Y_test = list(), list(), list(), list()\n",
    "    final_choices = [x[-1] for x in data]\n",
    "    features = [x[:-1] for x in data]\n",
    "    # making training data \n",
    "    count = 0\n",
    "    for feat,f_choice in zip(features, final_choices):\n",
    "        if(len(feat)//2 <= n_steps):\n",
    "            X_test.append(feat)\n",
    "            Y_test.append(f_choice)\n",
    "            X_train.append(feat)\n",
    "            Y_train.append(f_choice)\n",
    "            count += 1\n",
    "        else:\n",
    "            for i in range(len(feat)//2-n_steps):\n",
    "                end_idx = 2*(i+n_steps)\n",
    "                X_train.append(feat[2*i:end_idx])\n",
    "                Y_train.append(feat[end_idx])\n",
    "            X_test.append(feat[(len(feat)-2*n_steps):len(feat)])\n",
    "            Y_test.append(f_choice)\n",
    "    print(count)\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_outcomes(data):\n",
    "    maxi = max([max(x) for x in data])\n",
    "    mini = min([min(x) for x in data])\n",
    "    for i in range(len(data)):\n",
    "        for j in range(1,len(data[i]),2):\n",
    "            data[i][j] -= mini\n",
    "            data[i][j] /= (maxi-mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(name, n_steps):\n",
    "    infile = open(name, 'r')\n",
    "    lines = infile.readlines()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        data.append([float(x) for x in line.split(',')])\n",
    "#     normalise_outcomes(data)\n",
    "    return create_dataset(data, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n"
     ]
    }
   ],
   "source": [
    "n_steps=2\n",
    "X_train, y_train, X_test, y_test = parse_dataset('data/estimation_without_padding.csv',n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "# y_train -= 1\n",
    "# y_test -= 1\n",
    "\n",
    "X_train = pad_sequences(X_train, value=-50, padding='post', dtype=float)\n",
    "X_test = pad_sequences(X_test, value=-50, padding='post', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2. , -0.3,  1. , -0.3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], n_steps, 2))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], n_steps, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. , -0.3],\n",
       "       [ 2. , -0.3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=False, activation='relu', kernel_initializer='normal', input_shape=(None, X_train.shape[2])))\n",
    "# model.add(Dense(10))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                10600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 10,753\n",
      "Trainable params: 10,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((11250, 2, 2), (1170, 2, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11250 samples, validate on 1170 samples\n",
      "Epoch 1/10\n",
      "11250/11250 [==============================] - 60s 5ms/step - loss: 0.5406 - acc: 0.7410 - val_loss: 0.7567 - val_acc: 0.6256\n",
      "Epoch 2/10\n",
      "11250/11250 [==============================] - 60s 5ms/step - loss: 0.5078 - acc: 0.7648 - val_loss: 0.7378 - val_acc: 0.5624\n",
      "Epoch 3/10\n",
      "11250/11250 [==============================] - 59s 5ms/step - loss: 0.5042 - acc: 0.7666 - val_loss: 0.7269 - val_acc: 0.6274\n",
      "Epoch 4/10\n",
      "11250/11250 [==============================] - 60s 5ms/step - loss: 0.5031 - acc: 0.7701 - val_loss: 0.7650 - val_acc: 0.5393\n",
      "Epoch 5/10\n",
      "11250/11250 [==============================] - 61s 5ms/step - loss: 0.5005 - acc: 0.7711 - val_loss: 0.7211 - val_acc: 0.5632\n",
      "Epoch 6/10\n",
      "11250/11250 [==============================] - 58s 5ms/step - loss: 0.4995 - acc: 0.7704 - val_loss: 0.7415 - val_acc: 0.5376\n",
      "Epoch 7/10\n",
      " 5560/11250 [=============>................] - ETA: 28s - loss: 0.4971 - acc: 0.7721"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.predict(X_test[0:10]), y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=0\n",
    "for pred, truth in zip(predictions,y_test):\n",
    "    if(pred>=0.5 and truth==1):\n",
    "        ans += 1\n",
    "    if(pred<0.5 and  truth==0):\n",
    "        ans += 1\n",
    "ans*100.0/(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "1, 61.45\n",
    "2, 54.70\n",
    "3, 54.62\n",
    "5, 58.38\n",
    "10, 62.31\n",
    "20, 60.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1,2,3,5,10,20]\n",
    "y=[61.45, 54.70, 54.62, 58.38, 62.31, 60.00]\n",
    "plt.plot(x,y, '--bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
