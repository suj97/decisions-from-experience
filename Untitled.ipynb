{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujay/miniconda3/envs/mtp/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, GRU, SimpleRNN, Embedding, Conv1D, MaxPooling1D\n",
    "from keras import optimizers,regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, n_steps):\n",
    "    X_train, Y_train, X_test, Y_test = list(), list(), list(), list()\n",
    "    final_choices = [x[-1] for x in data]\n",
    "    features = [x[:-1] for x in data]\n",
    "    # making training data \n",
    "    for feat,f_choice in zip(features, final_choices):\n",
    "        if(len(feat)//2 <= n_steps):\n",
    "            X_test.append(feat)\n",
    "            Y_test.append(f_choice)\n",
    "            X_train.append(feat)\n",
    "            Y_train.append(f_choice)\n",
    "        else:\n",
    "            for i in range(len(feat)//2-n_steps):\n",
    "                end_idx = 2*(i+n_steps)\n",
    "                X_train.append(feat[2*i:end_idx])\n",
    "                Y_train.append(feat[end_idx])\n",
    "            X_test.append(feat[(len(feat)-2*n_steps):len(feat)])\n",
    "            Y_test.append(f_choice)\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(name, n_steps):\n",
    "    infile = open(name, 'r')\n",
    "    lines = infile.readlines()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        data.append([float(x) for x in line.split(',')])\n",
    "    return create_dataset(data, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=7\n",
    "X_train, y_train, X_test, y_test = parse_dataset('data/estimation_without_padding.csv',n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(X):\n",
    "\toutcomes = [i for i in range(1, len(X[0]), 2)]\n",
    "\t#X[:, outcomes] = minmax_scale(X[:, outcomes])\n",
    "\t#X[:, outcomes] = minmax_scale(X[:, outcomes])\n",
    "\tmini = np.min(X)\n",
    "\tmaxi = np.max(X)\n",
    "\tX[:, outcomes] -= mini\n",
    "\tX[:, outcomes] /=(maxi-mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train -= 1\n",
    "y_test -= 1\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', dtype=float)\n",
    "X_test = pad_sequences(X_test, padding='post', dtype=float)\n",
    "# normalize_columns(X_train)\n",
    "# normalize_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1. , -0.3,  2. , -0.3,  1. , -0.3,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], n_steps, 2))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], n_steps, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. , -0.3],\n",
       "       [ 2. , -0.3],\n",
       "       [ 1. , -0.3],\n",
       "       [ 0. ,  0. ],\n",
       "       [ 0. ,  0. ],\n",
       "       [ 0. ,  0. ],\n",
       "       [ 0. ,  0. ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=False, activation='relu', kernel_initializer='normal', input_shape=(None, X_train.shape[2])))\n",
    "model.add(Dropout(d))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7272, 7, 2), (1170, 7, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7272 samples, validate on 1170 samples\n",
      "Epoch 1/50\n",
      "7272/7272 [==============================] - 15s 2ms/step - loss: 0.6444 - acc: 0.6192 - val_loss: 0.7105 - val_acc: 0.5573\n",
      "Epoch 2/50\n",
      "7272/7272 [==============================] - 13s 2ms/step - loss: 0.5662 - acc: 0.7184 - val_loss: 0.7418 - val_acc: 0.5880\n",
      "Epoch 3/50\n",
      "7272/7272 [==============================] - 13s 2ms/step - loss: 0.5308 - acc: 0.7616 - val_loss: 0.7768 - val_acc: 0.5769\n",
      "Epoch 4/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.5097 - acc: 0.7772 - val_loss: 0.7679 - val_acc: 0.6060\n",
      "Epoch 5/50\n",
      "7272/7272 [==============================] - 13s 2ms/step - loss: 0.4802 - acc: 0.8051 - val_loss: 0.8526 - val_acc: 0.5846\n",
      "Epoch 6/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4629 - acc: 0.8240 - val_loss: 0.8267 - val_acc: 0.6060\n",
      "Epoch 7/50\n",
      "7272/7272 [==============================] - 13s 2ms/step - loss: 0.4504 - acc: 0.8321 - val_loss: 0.8401 - val_acc: 0.6009\n",
      "Epoch 8/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4450 - acc: 0.8340 - val_loss: 0.8499 - val_acc: 0.5923\n",
      "Epoch 9/50\n",
      "7272/7272 [==============================] - 15s 2ms/step - loss: 0.4429 - acc: 0.8359 - val_loss: 0.8364 - val_acc: 0.6103\n",
      "Epoch 10/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4321 - acc: 0.8420 - val_loss: 0.8241 - val_acc: 0.6068\n",
      "Epoch 11/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4305 - acc: 0.8464 - val_loss: 0.7942 - val_acc: 0.6103\n",
      "Epoch 12/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4304 - acc: 0.8445 - val_loss: 0.8375 - val_acc: 0.6068\n",
      "Epoch 13/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4238 - acc: 0.8479 - val_loss: 0.7788 - val_acc: 0.6120\n",
      "Epoch 14/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4206 - acc: 0.8468 - val_loss: 0.8688 - val_acc: 0.6120\n",
      "Epoch 15/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4173 - acc: 0.8483 - val_loss: 0.8630 - val_acc: 0.6145\n",
      "Epoch 16/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4203 - acc: 0.8494 - val_loss: 0.8324 - val_acc: 0.6162\n",
      "Epoch 17/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4155 - acc: 0.8479 - val_loss: 0.8063 - val_acc: 0.6188\n",
      "Epoch 18/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4152 - acc: 0.8512 - val_loss: 0.8486 - val_acc: 0.6120\n",
      "Epoch 19/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4116 - acc: 0.8524 - val_loss: 0.9123 - val_acc: 0.5829\n",
      "Epoch 20/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4132 - acc: 0.8509 - val_loss: 0.8245 - val_acc: 0.6282\n",
      "Epoch 21/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4089 - acc: 0.8534 - val_loss: 0.8215 - val_acc: 0.6299\n",
      "Epoch 22/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4098 - acc: 0.8527 - val_loss: 0.8465 - val_acc: 0.6239\n",
      "Epoch 23/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4064 - acc: 0.8522 - val_loss: 0.8482 - val_acc: 0.6368\n",
      "Epoch 24/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4076 - acc: 0.8533 - val_loss: 0.9201 - val_acc: 0.6368\n",
      "Epoch 25/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4063 - acc: 0.8533 - val_loss: 0.8726 - val_acc: 0.6325\n",
      "Epoch 26/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4056 - acc: 0.8555 - val_loss: 0.9482 - val_acc: 0.6299\n",
      "Epoch 27/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4080 - acc: 0.8544 - val_loss: 0.8641 - val_acc: 0.6444\n",
      "Epoch 28/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4018 - acc: 0.8523 - val_loss: 0.8653 - val_acc: 0.6154\n",
      "Epoch 29/50\n",
      "7272/7272 [==============================] - 14s 2ms/step - loss: 0.4042 - acc: 0.8533 - val_loss: 0.9395 - val_acc: 0.6368\n",
      "Epoch 30/50\n",
      "1340/7272 [====>.........................] - ETA: 12s - loss: 0.4084 - acc: 0.8500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-82b1706b9718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/mtp/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/mtp/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mtp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mtp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mtp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
