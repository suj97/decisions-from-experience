{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data):\n",
    "    X_train, Y_train= list(), list()\n",
    "    final_choices = [x[-1] for x in data]\n",
    "    features = [x[:-1] for x in data]\n",
    "    return features, final_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_test(data):\n",
    "    X_test, Y_test= list(), list()\n",
    "    final_choices = [x[-1] for x in data]\n",
    "    features = [x[:-1] for x in data]\n",
    "    return features, final_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_outcomes(data):\n",
    "    maxi = max([max(x) for x in data])\n",
    "    mini = min([min(x) for x in data])\n",
    "    for i in range(len(data)):\n",
    "        for j in range(1,len(data[i]),2):\n",
    "            data[i][j] -= mini\n",
    "            data[i][j] /= (maxi-mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(name, flag):\n",
    "    infile = open(name, 'r')\n",
    "    lines = infile.readlines()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        data.append([float(x) for x in line.split(',')])\n",
    "    normalise_outcomes(data)\n",
    "    if(flag):\n",
    "        return create_dataset(data)\n",
    "    else:\n",
    "        return create_dataset_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = parse_dataset('../data/estimation_without_padding.csv', 1)\n",
    "X_test, y_test = parse_dataset('../data/competition_without_padding.csv', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.09444444444444447,\n",
       " 2.0,\n",
       " 0.0685185185185185,\n",
       " 1.0,\n",
       " 0.09444444444444447,\n",
       " 1.0,\n",
       " 0.09444444444444447,\n",
       " 1.0,\n",
       " 0.09444444444444447,\n",
       " 1.0,\n",
       " 0.09444444444444447,\n",
       " 1.0,\n",
       " 0.09444444444444447,\n",
       " 1.0,\n",
       " 0.09444444444444447]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxlen = max(max([len(x) for x in X_train]), max([len(x) for x in X_test]))\n",
    "# X_train = pad_sequences(X_train, padding='post', value=0, dtype=float, maxlen=maxlen)\n",
    "# X_test = pad_sequences(X_test, padding='post', value=0, dtype=float, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima_forecast(orde, sor, tre, train,test):\n",
    "    model = sm.tsa.SARIMAX(endog=train['choice'], exog=train[['outcome']], order=orde, seasonal_order=sord, \n",
    "                           trend=tre , enforce_invertibility=False, enforce_stationarity=False)\n",
    "    start_params = np.r_[[0] * (model.k_params - 1), 1]\n",
    "    result = model.fit(start_params=start_params, disp=False)\n",
    "#     result=model.fit()\n",
    "    yhat = result.predict(start = len(train), end = len(train), exog=test[['outcome']])\n",
    "    return yhat[len(train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(l, n):\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_performance(X_train, X_test, y_train, y_test, orde, sord, tren):\n",
    "    # for train\n",
    "    \n",
    "    train_score, test_score=0,0\n",
    "    predictions=[]\n",
    "    for (idx,each) in enumerate(X_train):\n",
    "        each = to_matrix(each,2)\n",
    "        df = pd.DataFrame(each)\n",
    "        df.columns = ['choice', 'outcome']\n",
    "        df_train, df_test = df[:-1], df[-1:]\n",
    "        for index,i in df_test.iterrows():\n",
    "            yhat = sarima_forecast(orde, sord, tren, df_train, df_test)\n",
    "            predictions.append(yhat)\n",
    "    #       train = train.append(i)\n",
    "    #       rmse = sqrt(mean_squared_error(df_te['MTTR'].values,predictions))\n",
    "    #       combo = orde, sord, tren, rmse\n",
    "    #       error.append(combo)\n",
    "    #        print(yhat, y_train[idx])\n",
    "    predictions_train=[]\n",
    "    for pred in predictions:\n",
    "        if(abs(pred-1)>abs(pred-2)):\n",
    "            predictions_train.append(2)\n",
    "        else:\n",
    "            predictions_train.append(1)\n",
    "    train_score = accuracy_score(predictions_train, y_train)\n",
    "    \n",
    "    \n",
    "    # for test\n",
    "    \n",
    "    predictions=[]\n",
    "    for (idx,each) in enumerate(X_test):\n",
    "        each = to_matrix(each,2)\n",
    "        df = pd.DataFrame(each)\n",
    "        df.columns = ['choice', 'outcome']\n",
    "\n",
    "        df_train, df_test = df[:-1], df[-1:]\n",
    "        for index,i in df_test.iterrows():\n",
    "            yhat = sarima_forecast(orde, sord, tren, df_train, df_test)\n",
    "            predictions.append(yhat)\n",
    "    \n",
    "    predictions_test=[]\n",
    "    for pred in predictions:\n",
    "        if(abs(pred-1)>abs(pred-2)):\n",
    "            predictions_test.append(2)\n",
    "        else:\n",
    "            predictions_test.append(1)\n",
    "    test_score = accuracy_score(predictions_test, y_test)\n",
    "    \n",
    "    return (train_score, test_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] [0, 0, 0, 0] n (0.552991452991453, 0.4791318864774624)\n",
      "[0, 0, 0] [1, 0, 1, 0] n (0.5692307692307692, 0.5592654424040067)\n",
      "[0, 0, 0] [2, 0, 2, 0] n (0.5641025641025641, 0.5575959933222037)\n",
      "[0, 0, 0] [0, 0, 0, 0] c (0.5769230769230769, 0.5601001669449082)\n",
      "[0, 0, 0] [1, 0, 1, 0] c (0.564957264957265, 0.5667779632721202)\n",
      "[0, 0, 0] [2, 0, 2, 0] c (0.558974358974359, 0.5400667779632721)\n",
      "[0, 0, 0] [0, 0, 0, 0] t (0.49914529914529915, 0.48998330550918195)\n",
      "[0, 0, 0] [1, 0, 1, 0] t (0.5572649572649573, 0.5392320534223706)\n",
      "[0, 0, 0] [2, 0, 2, 0] t (0.5641025641025641, 0.5400667779632721)\n",
      "[0, 0, 0] [0, 0, 0, 0] ct (0.5495726495726496, 0.5409015025041736)\n",
      "[0, 0, 0] [1, 0, 1, 0] ct (0.5683760683760684, 0.5484140233722872)\n",
      "[0, 0, 0] [2, 0, 2, 0] ct (0.5632478632478632, 0.5417362270450752)\n"
     ]
    }
   ],
   "source": [
    "# define config lists\n",
    "p_params = [0, 1, 2]\n",
    "d_params = [0, 1]\n",
    "q_params = [0, 1, 2] \n",
    "P_params = [0, 1, 2]\n",
    "D_params = [0, 1]\n",
    "Q_params = [0, 1, 2]\n",
    "t_params = ['n','c','t','ct']\n",
    "m = 0 #seasonal\n",
    "\n",
    "configs=[]\n",
    "\n",
    "# create config instances\n",
    "for p in p_params:\n",
    "    for d in d_params:\n",
    "        for q in q_params:\n",
    "            for t in t_params:\n",
    "                for P in P_params:\n",
    "                    for D in D_params:\n",
    "                        for Q in Q_params:\n",
    "                            orde = [p,d,q]\n",
    "                            sord = [P,D,Q,m]\n",
    "                            tren = t\n",
    "                            \n",
    "                            configs.append([(p,d,q), (P,D,Q,m), t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_run():\n",
    "    train_score, test_score = 0,0\n",
    "    try:\n",
    "    # never show warnings when grid searching, too noisy\n",
    "        with catch_warnings():\n",
    "        filterwarnings(\"ignore\")\n",
    "        (train_score, test_score) = check_performance(X_train, X_test, y_train, y_test,\n",
    "                                                                             orde, sord, tren)\n",
    "    except:\n",
    "        train_score, test_score = None, None\n",
    "                            \n",
    "        if(train_score is not None):\n",
    "            print(orde, sord, tren, (train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing') \n",
    "tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list) \n",
    "scores = executor(tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions=[]\n",
    "# for (idx,each) in enumerate(X_train):\n",
    "#     each = to_matrix(each,2)\n",
    "#     df = pd.DataFrame(each)\n",
    "#     df.columns = ['choice', 'outcome']\n",
    "    \n",
    "#     df_train, df_test = df[:-1], df[-1:]\n",
    "    \n",
    "#     tr = ['n']\n",
    "#     error = []\n",
    "#     for p in ([1]):\n",
    "#         for q in ([1]):\n",
    "#             for P in ([1]):\n",
    "#                     for Q in ([1]):\n",
    "#                         for m in ([5]):\n",
    "#                             for t in tr:\n",
    "#                                 orde = [p,1,q]\n",
    "#                                 sord = [P,0,Q,m]\n",
    "#                                 tren = t\n",
    "#                                 for index,i in df_test.iterrows():\n",
    "#                                     yhat = sarima_forecast(orde, sord, tren, df_train, df_test)\n",
    "#                                     predictions.append(yhat)\n",
    "# #                                     train = train.append(i)\n",
    "# #                                 rmse = sqrt(mean_squared_error(df_te['MTTR'].values,predictions))\n",
    "# #                                 combo = orde, sord, tren, rmse\n",
    "# #                                 error.append(combo)\n",
    "#                                     print(yhat, y_train[idx])\n",
    "# #                                 print (orde, sord, tren, rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_train=[]\n",
    "# for pred in predictions:\n",
    "#     if(abs(pred-1)>abs(pred-2)):\n",
    "#         predictions_train.append(2)\n",
    "#     else:\n",
    "#         predictions_train.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions=[]\n",
    "# for (idx,each) in enumerate(X_test):\n",
    "#     each = to_matrix(each,2)\n",
    "#     df = pd.DataFrame(each)\n",
    "#     df.columns = ['choice', 'outcome']\n",
    "    \n",
    "#     df_train, df_test = df[:-1], df[-1:]\n",
    "    \n",
    "#     tr = ['n']\n",
    "#     error = []\n",
    "#     for p in ([1]):\n",
    "#         for q in ([1]):\n",
    "#             for P in ([1]):\n",
    "#                     for Q in ([1]):\n",
    "#                         for m in ([5]):\n",
    "#                             for t in tr:\n",
    "#                                 orde = [p,1,q]\n",
    "#                                 sord = [P,0,Q,m]\n",
    "#                                 tren = t\n",
    "#                                 for index,i in df_test.iterrows():\n",
    "#                                     yhat = sarima_forecast(orde, sord, tren, df_train, df_test)\n",
    "#                                     predictions.append(yhat)\n",
    "# #                                     train = train.append(i)\n",
    "# #                                 rmse = sqrt(mean_squared_error(df_te['MTTR'].values,predictions))\n",
    "# #                                 combo = orde, sord, tren, rmse\n",
    "# #                                 error.append(combo)\n",
    "#                                     print(yhat, y_test[idx])\n",
    "# #                                 print (orde, sord, tren, rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_train=[]\n",
    "# for pred in predictions:\n",
    "#     if(abs(pred-1)>abs(pred-2)):\n",
    "#         predictions_train.append(2)\n",
    "#     else:\n",
    "#         predictions_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(predictions_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
